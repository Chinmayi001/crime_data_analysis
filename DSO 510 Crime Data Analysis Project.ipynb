{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d405574c-7722-4418-8e84-103b48b95751",
   "metadata": {},
   "source": [
    "# DSO 510 PROJECT TEAM 3\n",
    "\n",
    "1. Chinmayi Bengaluru Prakash\n",
    "2. Daniel Strangio\n",
    "3. Hemanth Mallagatta Ravishankar\n",
    "4. Naveen Kumar Manjunatha\n",
    "5. Sravanthi Kuchibhotla\n",
    "6. Vicky Choi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b2c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:25.029375Z",
     "start_time": "2021-12-06T03:37:23.356555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343e509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:26.861990Z",
     "start_time": "2021-12-06T03:37:25.030466Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "df_raw = pd.read_csv(\"Crime Data_Nov2018_Present.csv\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2aa30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:26.870055Z",
     "start_time": "2021-12-06T03:37:26.863397Z"
    }
   },
   "outputs": [],
   "source": [
    "df_raw.Year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74bd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:27.183681Z",
     "start_time": "2021-12-06T03:37:26.871334Z"
    }
   },
   "outputs": [],
   "source": [
    "df_raw = df_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bb9e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:27.216805Z",
     "start_time": "2021-12-06T03:37:27.184691Z"
    }
   },
   "outputs": [],
   "source": [
    "#Filtering for the required columns\n",
    "columns = ['ID','Case Number','Date','Block','Primary Type', 'Description', 'Location Description', 'Arrest', 'Domestic', 'Year'\n",
    "          ,'Latitude', 'Longitude']\n",
    "df = df_raw[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55a0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:27.480630Z",
     "start_time": "2021-12-06T03:37:27.218263Z"
    }
   },
   "outputs": [],
   "source": [
    "#Distribution of Crime Incidents by Crime Type\n",
    "\n",
    "df1 = round((df[\"Primary Type\"].value_counts(normalize = True)*100),2).sort_values(ascending = True)\n",
    "\n",
    "\n",
    "plt.figure(figsize = [10,10])\n",
    "\n",
    "plt.title('Distribution of Crime Incidents by Type', fontweight='bold')\n",
    "plt.ylabel('Crime Type', fontweight='bold')\n",
    "plt.xlabel('Percentage of Total', fontweight='bold')\n",
    "\n",
    "\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"\", [\"green\",\"yellow\",\"red\"])\n",
    "\n",
    "plt.barh(df1.index,df1, color = cmap(df1.values/df1.values.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56543a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:27.514572Z",
     "start_time": "2021-12-06T03:37:27.481573Z"
    }
   },
   "outputs": [],
   "source": [
    "#Based on the results categorizing the Crime type into Frequency buckets\n",
    "\n",
    "c_high = ['THEFT','BATTERY','CRIMINAL DAMAGE','ASSAULT','DECEPTIVE PRACTICE','OTHER OFFENSE']\n",
    "c_mid = ['MOTOR VEHICLE THEFT','NARCOTICS','BURGLARY','ROBBERY','WEAPONS VIOLATION','CRIMINAL TRESPASS']\n",
    "c_combined = c_high + c_mid\n",
    "c_all = list(df[\"Primary Type\"].unique())\n",
    "c_all\n",
    "\n",
    "for element in c_combined:\n",
    "    if element in c_all:\n",
    "         c_all.remove(element)\n",
    "c_low = c_all            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e8dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:28.678283Z",
     "start_time": "2021-12-06T03:37:27.515407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Frequency Column based on Crime type\n",
    "\n",
    "df['Frequency']  = df['Primary Type']\n",
    "for i in c_high:\n",
    "    df['Frequency'].replace({i: \"High\"}, inplace=True)\n",
    "for i in c_mid:\n",
    "    df['Frequency'].replace({i: \"Mid\"}, inplace=True)\n",
    "for i in c_low:\n",
    "    df['Frequency'].replace({i: \"Low\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff324f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:28.714110Z",
     "start_time": "2021-12-06T03:37:28.680584Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the Severity variable based on the level of Punishment defined by the Law\n",
    "#L1-2 = low severity, L3-4 = medium severity, L5+ = high severity\n",
    "#https://pap.georgia.gov/sites/pap.georgia.gov/files/CSL-s_Post_1-1-2006_considerations.pdf\n",
    "\n",
    "\n",
    "df['Severity'] = df['Primary Type']\n",
    "\n",
    "sev_High = [\"HUMAN TRAFFICKING\", \"KIDNAPPING\", \"ROBBERY\", \"PROSTITUTION\", \"CRIM SEXUAL ASSAULT\", \"CRIMINAL SEXUAL ASSAULT\", \"SEX OFFENSE\", \"OFFENSE INVOLVING CHILDREN\", \"ASSAULT\", \"BATTERY\", ]\n",
    "sev_Mid = [\"NARCOTICS\", \"BURGLARY\", \"WEAPONS VIOLATION\", \"HOMICIDE\", \"ARSON\" ]\n",
    "sev_combined = sev_High + sev_Mid\n",
    "sev_all = list(df[\"Primary Type\"].unique())\n",
    "sev_all\n",
    "\n",
    "for element in sev_combined:\n",
    "    if element in sev_all:\n",
    "         sev_all.remove(element)\n",
    "sev_Low = sev_all  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e37b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:29.856137Z",
     "start_time": "2021-12-06T03:37:28.715883Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in sev_High:\n",
    "    df['Severity'].replace({i: \"High\"}, inplace=True)\n",
    "for i in sev_Mid:\n",
    "    df['Severity'].replace({i: \"Mid\"}, inplace=True)\n",
    "for i in sev_Low:\n",
    "    df['Severity'].replace({i: \"Low\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296cec2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:50.722388Z",
     "start_time": "2021-12-06T03:37:29.857129Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding Day of the week column to the dataset\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "df['dayofweek'] = df['Date'].dt.strftime(\"%A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f226e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:51.074350Z",
     "start_time": "2021-12-06T03:37:50.723433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating Day-Night Variable\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Time'] = df['Date'].dt.time\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "df['DayNight'] = ['Day' if x >= 6 and x <= 18 else 'Night' for x in df['Hour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944a906-f985-441a-a7e9-5f947596e0c0",
   "metadata": {},
   "source": [
    "## EDA and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e08ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:51.077731Z",
     "start_time": "2021-12-06T03:37:51.075305Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116c585-08dc-4405-9903-de457caf6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crimes per day of the week\n",
    "\n",
    "graph_data = pd.DataFrame(df.groupby('dayofweek')['Arrest'].sum()).reset_index()\n",
    "graph_data\n",
    "\n",
    "fig = px.bar(graph_data, x='dayofweek', y='Arrest',\n",
    "             hover_data=['dayofweek', 'Arrest'], \n",
    "             #color='Arrest',\n",
    "             labels=dict(dayofweek=\"Day of Week\", Arrest=\"Number of Crime Incidents\"), \n",
    "             height=400)\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Weekly Number of Crime Incidents\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d56bb3-b860-4a6f-abae-4b372cedd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrests per day of the week \n",
    "\n",
    "graph_data1 = pd.DataFrame(df.groupby(['dayofweek','Arrest'])['ID'].count().sort_values(ascending = False)).reset_index()\n",
    "graph_data1\n",
    "\n",
    "fig = px.bar(graph_data1, x='dayofweek', y='ID',\n",
    "             hover_data=['dayofweek', 'Arrest'], \n",
    "             color='Arrest',\n",
    "             labels=dict(dayofweek=\"Day of Week\", ID=\"Number of Arrests\"), \n",
    "             height=400,\n",
    "             title='Weekly Number of Arrests')\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Weekly Number of Arrests\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb5440-5c40-4de9-bd53-7c704d5721c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severity vs. Frequency\n",
    "\n",
    "sns.histplot(binwidth=0.5, x=\"Frequency\", hue=\"Severity\", data=df, stat=\"count\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998afbc-9634-42d4-9be5-11434e858046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day']=df['Date'].dt.day\n",
    "\n",
    "graph_data3 = pd.DataFrame(df.groupby('Day')['Arrest'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1d96b-f0e2-4b27-8d06-5c216a260c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crimes per day of the month\n",
    "\n",
    "df['Day']=df['Date'].dt.day\n",
    "\n",
    "graph_data3 = pd.DataFrame(df.groupby('Day')['Arrest'].sum()).reset_index()\n",
    "\n",
    "fig = px.bar(graph_data3, x='Day', y='Arrest',\n",
    "             hover_data=['Day', 'Arrest'], \n",
    "             color='Arrest',\n",
    "             labels=dict(Day=\"Day of Month\", Arrest=\"Daily Number of Crime Incidents\"), \n",
    "             height=400)\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Daily Number of Crime Incidents\",\n",
    "        'y':0.9,\n",
    "        'x':0.4,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77ee33-185f-4d3b-be8f-312f645ae502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Arrests by Frequency Type\n",
    "\n",
    "pd.crosstab(df.Frequency,df.Arrest).plot(kind='bar')\n",
    "plt.title('Number of Arrests for Frequency Type')\n",
    "plt.xlabel('Frequency Type')\n",
    "plt.ylabel('Number of Arrests')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521e202-ccc1-4db6-8fdc-dc2c75d84d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrests vs. Time of Day\n",
    "\n",
    "sns.catplot(x = 'Arrest', kind ='count', hue='DayNight', data = df, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398850f3-c497-404d-ad15-4765d3785ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrest vs. Domestic or Non- Domestic\n",
    "\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "df2 = df[['Domestic', 'Arrest']]\n",
    "df2[\"Domestic\"].replace({True: \"Domestic\", False: \"Non-Domestic\"}, inplace=True)\n",
    "df2[\"Arrest\"].replace({True: \"Arrest\", False: \"No Arrest\"}, inplace=True)\n",
    "\n",
    "props={}\n",
    "props[('Domestic','Arrest')]={'facecolor':'red', 'edgecolor':'white'}\n",
    "props[('Domestic','No Arrest')]={'facecolor':'xkcd:aqua', 'edgecolor':'white'}\n",
    "props[('Non-Domestic','Arrest')]={'facecolor':'red','edgecolor':'white'}\n",
    "props[('Non-Domestic','No Arrest')]=        {'facecolor':'xkcd:aqua','edgecolor':'white'}\n",
    "\n",
    "mosaic(df2, ['Domestic', 'Arrest'], title = 'Does arrest depend on type of incident?', properties=props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf143b-5c47-4a7d-8953-73790160d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Date'] = pd.to_datetime(df_raw.Date)\n",
    "df_raw['Date-Month'] = df_raw['Date'].dt.to_period('M')\n",
    "df_raw['Month'] = df_raw.Date.dt.month\n",
    "\n",
    "g2_data = pd.DataFrame(df_raw.groupby(['Month','Arrest'])['ID'].count()/3).reset_index()\n",
    "\n",
    "sorterIndex = {1 : 'Jan' ,2 : 'Feb', 3 : 'Mar', 4 : 'Apr', 5 : 'May',6 : 'Jun' ,7 : 'Jul' ,8 : 'Aug',9 : 'Sep',10 : 'Oct',11 : 'Nov',12 : 'Dec'\n",
    "              }\n",
    "\n",
    "g2_data['month_name'] = g2_data['Month']\n",
    "g2_data['month_name'] = g2_data['Month'].map(sorterIndex)\n",
    "\n",
    "g2_data.sort_values('Month', inplace=True)\n",
    "g2_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efaa193-f4fa-40b4-b9c1-734f3c395b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(g2_data, x='month_name', y='ID', color = 'Arrest',\n",
    "             hover_data=['month_name', 'ID'],\n",
    "             labels={'month_name':'Month of Year','ID':'Average # Cases'}, \n",
    "             title= \"Average # Cases by month, split by arrest\",\n",
    "             height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc6211-cd6d-4ac7-9c52-a3ec321cee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Date'] = pd.to_datetime(df_raw.Date)\n",
    "df_raw['Date-Month'] = df_raw['Date'].dt.to_period('M')\n",
    "df_raw['Month'] = df_raw.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4a855-d9a8-4397-b108-83f6bf2cff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_line = df_raw.groupby(['Year','Month','Date-Month'])[['ID']].count().reset_index().rename(columns = {'ID': 'Total Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f8b99-9923-42fc-8358-4af1a7f8d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crimes by Month YoY\n",
    "fig = px.line(df_line, x='Month', y=\"Total Count\", color = 'Year', title='Crimes by Month YoY')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce7581-a1c7-4bd2-a8d3-a998910b71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = pd.DataFrame(df.groupby(['dayofweek','Arrest'])['ID'].count()).reset_index().rename(columns = {'ID': 'Total Count'})\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f41de8-28fc-41fa-b6a8-2f23ae9d4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorterIndex = {'Friday': 5,\n",
    " 'Monday': 1,\n",
    " 'Saturday': 6,\n",
    " 'Sunday': 0,\n",
    " 'Thursday': 4,\n",
    " 'Tuesday': 2,\n",
    " 'Wednesday': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7125a-d009-43d0-9e40-741572c7411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_data\n",
    "\n",
    "graph_data['Day_id'] = graph_data['dayofweek']\n",
    "graph_data['Day_id'] = graph_data['Day_id'].map(sorterIndex)\n",
    "\n",
    "graph_data.sort_values('Day_id', inplace=True)\n",
    "graph_data.head()\n",
    "\n",
    "#data_canada = data[data.country == 'Canada']\n",
    "fig = px.bar(graph_data, x='dayofweek', y='Total Count', color = 'Arrest',\n",
    "             hover_data=['dayofweek', 'Total Count'], \n",
    "             labels={'dayofweek':'Day of Week','Total Count':'# Cases'},\n",
    "             title = '# Cases by Day of the Week', \n",
    "             height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f52af-74f2-4218-84b4-fb15920a49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c57bfe-d85e-4b9c-8047-8a8ef88e98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "m = folium.Map([41.8781, -87.6298], zoom_start=11)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb8d70-8462-4de9-8724-4a5ddfae933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to (n, 2) nd-array format for heatmap\n",
    "stationArr = df[['Latitude', 'Longitude']].to_numpy()\n",
    "\n",
    "\n",
    "stationArr\n",
    "#plot heatmap\n",
    "m.add_children(plugins.HeatMap(stationArr, radius=15))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045e1ee-30bc-42fb-b9ac-909efc7e8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2222668-2c12-4bbe-80b2-8e84b59a56aa",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7c656-cc73-4c79-92c6-bd34b1095269",
   "metadata": {},
   "source": [
    "Hypothesis: Incidents that occur during the night are more prone to arrests or not\n",
    "\n",
    "Let p1 be the proportion of arrests during night \\\n",
    "Let p2 be the proportion of arrests during day \n",
    "\n",
    "Null Hypothesis Ho: Proportion of arrests during night is lesser than or equal to proportion of arrests during daytime p1 <= p2 \\\n",
    "Alternative Hypothesis Ha: Proportion of arrests during night is more than proportion of arrests during daytime p1 > p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115c70f-415b-4d85-a2f5-3779fc314e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night = df.loc[df[\"DayNight\"]=='Night']\n",
    "\n",
    "df_day = df.loc[df[\"DayNight\"]=='Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b9f31-4167-4419-8b52-6b80452ad128",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = round(df_night[df['Arrest'] == True]['Arrest'].count()/df_night['Arrest'].count(),5)\n",
    "p2 = round(df_day[df['Arrest'] == True]['Arrest'].count()/df_day['Arrest'].count(),5)\n",
    "\n",
    "print(\"p1:\",p1)\n",
    "print(\"p2:\",p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd9dcf-f02e-4e35-a442-b865723c6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = df_night['Arrest'].count()\n",
    "n2 = df_day['Arrest'].count()\n",
    "\n",
    "print(\"n1:\",n1)\n",
    "print(\"n2:\",n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65510d-504d-4fe1-ad7b-31597e487784",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_obs = (p1 - p2) / math.sqrt(((p2*(1-p2))/n2) + ((p1*(1-p1))/n1))\n",
    "print(\"z_obs: \",z_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c740757-6b4a-4505-902b-eead78bf5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d972c1c-6182-4ebd-aada-03ecb8ea667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = (1-st.norm.cdf(z_obs))\n",
    "print(\"p_value: \",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4852ae-a496-42ce-a0e8-4669a4409f5f",
   "metadata": {},
   "source": [
    "Taking 95% Confidence Interval, since p-value is lesser than 0.05, we can reject null hypothesis and conclude that the proportion of incidents proning to arrests is more during the night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737187ed-33d2-4053-b109-860b52ba44b8",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for Arrests vs. Domestic/ Non-Domestic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c09109-4720-4a36-ad5e-1c9e8d866e38",
   "metadata": {},
   "source": [
    "Hypothesis: Probability of an arrest is higher in non-domestic incidents compared to domestic incidents\n",
    "\n",
    "Let p1 be the proportion of arrests in non-domestic incidents\n",
    "<br>\n",
    "Let p2 be the proportion of arrests in domestic incidents\n",
    "\n",
    "Null Hypothesis: There is no difference between the proportion of arrests in domestic and non-domestic incidents ( p1-p2 ) = 0\n",
    "<br>\n",
    "Alternate Hypothesis: The proportion of arrests in non-domestic incidents is greater than domestic incidents ( p1-p2 ) > 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5821fa5-6ee4-49fd-ad8d-77d67ac88c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = df2[(df2[\"Domestic\"]==\"Non-Domestic\") & (df2[\"Arrest\"]=='Arrest')]['Arrest'].count()/df2[(df2[\"Domestic\"]==\"Non-Domestic\")]['Arrest'].count()\n",
    "p2 = df2[(df2[\"Domestic\"]==\"Domestic\") & (df2[\"Arrest\"]=='Arrest')]['Arrest'].count()/df2[(df2[\"Domestic\"]==\"Domestic\")]['Arrest'].count() \n",
    "n1 = df2[(df2[\"Domestic\"]==\"Non-Domestic\")]['Arrest'].count()\n",
    "n2 = df2[(df2[\"Domestic\"]==\"Domestic\")]['Arrest'].count() \n",
    "print(f'Proportion of arrests in non-domestic incidents; p1 = {p1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab32a69-b0df-42e7-8200-4d773d97de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (p1 - p2)/math.sqrt(((p1*(1-p1))/n1) + ((p2*(1-p2))/n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d025c-fbce-4226-9ee5-32bd5a71265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = (1 - st.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9c396-b752-472b-8318-26df15cd1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006bcec-dcf5-41c6-aac7-e1d23eab712c",
   "metadata": {},
   "source": [
    "Since p-value is almost 0 we can reject the null hypothesis and conclude that the Probablilty of an Arrest occuring in a non-domestic incident is greater than a domestic incident"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31310a",
   "metadata": {},
   "source": [
    "## Model to predict whether the criminal incident will lead to an arrest or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc011ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:51.459811Z",
     "start_time": "2021-12-06T03:37:51.078685Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating Dummies for Categorical variables\n",
    "\n",
    "df['Domestic'].replace({True: \"Domestic\", False: 'Non Domestic'}, inplace=True)\n",
    "df_model = pd.get_dummies(df, columns= ['DayNight','Domestic','dayofweek','Frequency','Severity'])\n",
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:51.505965Z",
     "start_time": "2021-12-06T03:37:51.460704Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model.drop(['ID', 'Case Number', 'Date', 'Block', 'Primary Type', 'Description',\n",
    "       'Location Description','Year', 'Latitude', 'Longitude',\n",
    "       'Time', 'Hour','DayNight_Day','Domestic_Non Domestic', 'dayofweek_Sunday', 'Frequency_High', \n",
    "               'Severity_High' ], axis=1, inplace = True)\n",
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e26a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:51.547810Z",
     "start_time": "2021-12-06T03:37:51.506954Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining Target variable as 1, 0\n",
    "df_model['Arrest'].replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "df_model.head()\n",
    "data_final = df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760736ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:37:53.032420Z",
     "start_time": "2021-12-06T03:37:51.548815Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26cad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:08.813341Z",
     "start_time": "2021-12-06T03:37:53.034643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Over-sampling using SMOTE\n",
    "# With our training data created, I’ll up-sample the no-subscription using the SMOTE algorithm(Synthetic Minority Oversampling Technique). \n",
    "# At a high level, SMOTE:\n",
    "# Works by creating synthetic samples from the minor class (no-subscription) instead of creating copies.\n",
    "# Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations.\n",
    "\n",
    "X = data_final.loc[:, data_final.columns != 'Arrest']\n",
    "y = data_final.loc[:, data_final.columns == 'Arrest']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Arrest'])\n",
    "\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no Arrest in oversampled data\",len(os_data_y[os_data_y['Arrest']==0]))\n",
    "print(\"Number of Arrests\",len(os_data_y[os_data_y['Arrest']==1]))\n",
    "print(\"Proportion of no Arrest data in oversampled data is \",len(os_data_y[os_data_y['Arrest']==0])/len(os_data_X))\n",
    "print(\"Proportion of Arrest data in oversampled data is \",len(os_data_y[os_data_y['Arrest']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e357e8f",
   "metadata": {},
   "source": [
    "Now we have a perfect balanced data! You may have noticed that I over-sampled only on the training data, because by oversampling only on the training data, none of the information in the test data is being used to create synthetic observations, therefore, no information will bleed from test data into the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7ba83",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination\n",
    "Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a67c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:09.552614Z",
     "start_time": "2021-12-06T03:38:08.814329Z"
    }
   },
   "outputs": [],
   "source": [
    "data_final_vars=data_final.columns.values.tolist()\n",
    "y=['Arrest']\n",
    "X=[i for i in data_final_vars if i not in y]\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c871a10",
   "metadata": {},
   "source": [
    "The RFE has helped us select the following features used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f832eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:10.593630Z",
     "start_time": "2021-12-06T03:38:09.554057Z"
    }
   },
   "outputs": [],
   "source": [
    "#Building the Logistic Regression Model to predict the Arrest happening\n",
    "\n",
    "X=os_data_X\n",
    "y=os_data_y['Arrest']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1d4e2",
   "metadata": {},
   "source": [
    "The p-values for most of the variables are smaller than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb939221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.241520Z",
     "start_time": "2021-12-06T03:38:10.594715Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a0ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.271683Z",
     "start_time": "2021-12-06T03:38:11.242614Z"
    }
   },
   "outputs": [],
   "source": [
    "#Predicting the test set results and calculating the accuracy\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0ad9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.386031Z",
     "start_time": "2021-12-06T03:38:11.272766Z"
    }
   },
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa1dfd",
   "metadata": {},
   "source": [
    "The result is telling us that we have 103344+54997 correct predictions and 15510+63954 incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8373a",
   "metadata": {},
   "source": [
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac38d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.588964Z",
     "start_time": "2021-12-06T03:38:11.387155Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522ad31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.771743Z",
     "start_time": "2021-12-06T03:38:11.589878Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67497c",
   "metadata": {},
   "source": [
    "The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e1963",
   "metadata": {},
   "source": [
    "## Model to predict the number of crime incidents per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc5c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.786869Z",
     "start_time": "2021-12-06T03:38:11.772865Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0fbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.954045Z",
     "start_time": "2021-12-06T03:38:11.792951Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding month column to dataset\n",
    "\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "df.head()\n",
    "\n",
    "df_criminal_incidents = df.groupby(['DayNight', 'Domestic', 'Frequency', 'Severity', 'Year', 'Month'])['ID'].count().reset_index().rename(columns={'ID':'Total_count'})\n",
    "df_criminal_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c89a2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.969126Z",
     "start_time": "2021-12-06T03:38:11.957330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "print(df_criminal_incidents.info())\n",
    "\n",
    "# Checking for outliers\n",
    "print(df_criminal_incidents.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0726e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.974762Z",
     "start_time": "2021-12-06T03:38:11.969992Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating dummy variables for categorical variables\n",
    "\n",
    "df_model = pd.get_dummies(df_criminal_incidents, columns= ['DayNight','Domestic','Frequency','Severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4c9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.982841Z",
     "start_time": "2021-12-06T03:38:11.975748Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_model.head()\n",
    "data_final = df_model.drop(['Year', 'Month', 'Domestic_Non Domestic', 'Frequency_High', 'Severity_High', 'DayNight_Day'] ,axis = 1)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3da6d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:11.987148Z",
     "start_time": "2021-12-06T03:38:11.983882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building a linear model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(data_final, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2da594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.007475Z",
     "start_time": "2021-12-06T03:38:11.988236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividing the training data set into X and Y\n",
    "y_train = df_train.pop('Total_count')\n",
    "X_train = df_train\n",
    "\n",
    "#Build a linear model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "\n",
    "lr_1 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "lr_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d462fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.036816Z",
     "start_time": "2021-12-06T03:38:12.009240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for the VIF values of the variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Creating a dataframe that will contain the names of all the feature variables and their VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67eeb64",
   "metadata": {},
   "source": [
    "Variance Inflation Factor or VIF is a quantitative value that says how much the feature variables are correlated with each other. It is an extremely important parameter to test our linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a9575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.140004Z",
     "start_time": "2021-12-06T03:38:12.038057Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "y_train_predicted = lr_1.predict(X_train_lm)\n",
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_predicted), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badaf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.146197Z",
     "start_time": "2021-12-06T03:38:12.141213Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8c411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.150960Z",
     "start_time": "2021-12-06T03:38:12.147346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing on Test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(data_final, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cd8b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.157252Z",
     "start_time": "2021-12-06T03:38:12.152427Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = df_test.pop('Total_count')\n",
    "X_test = df_test\n",
    "\n",
    "# Now let's use our model to make predictions.\n",
    "\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_test_new = X_test[X_train.columns]\n",
    "\n",
    "# Adding a constant variable \n",
    "X_test_new = sm.add_constant(X_test)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = lr_1.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6a48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.162639Z",
     "start_time": "2021-12-06T03:38:12.158588Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a79522",
   "metadata": {},
   "source": [
    "The R² value for the test data = 0.5907543414367202, which is pretty similar to the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f3d561",
   "metadata": {},
   "source": [
    "## Model to predict the number of crime incidents per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb1c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.288309Z",
     "start_time": "2021-12-06T03:38:12.164097Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arrests = df[df['Arrest'] == True].groupby(['DayNight', 'Domestic', 'Frequency', 'Severity', 'Year', 'Month'])['ID'].count().reset_index().rename(columns={'ID':'Total_arrests'})\n",
    "df_arrests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b1da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.294521Z",
     "start_time": "2021-12-06T03:38:12.289313Z"
    }
   },
   "outputs": [],
   "source": [
    "df_criminal_incidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ee8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.301266Z",
     "start_time": "2021-12-06T03:38:12.295482Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arrest_model = df_arrests.merge(df_criminal_incidents, how='inner', on=['DayNight', 'Domestic', 'Frequency', 'Severity', 'Year', 'Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3110c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.313044Z",
     "start_time": "2021-12-06T03:38:12.302255Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model = pd.get_dummies(df_arrest_model, columns= ['DayNight','Domestic','Frequency','Severity'])\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ec0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.325997Z",
     "start_time": "2021-12-06T03:38:12.314013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719ac3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.334286Z",
     "start_time": "2021-12-06T03:38:12.327557Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_model.head()\n",
    "data_final = df_model.drop(['Year', 'Month', 'Domestic_Non Domestic', 'Frequency_High', 'Severity_High', 'DayNight_Night'] ,axis = 1)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096d38f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.338361Z",
     "start_time": "2021-12-06T03:38:12.335212Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(data_final, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d181c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.354837Z",
     "start_time": "2021-12-06T03:38:12.339364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividing the training data set into X and Y\n",
    "y_train = df_train.pop('Total_arrests')\n",
    "X_train = df_train\n",
    "\n",
    "#Build a linear model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "\n",
    "lr_1 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "lr_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273c272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.362987Z",
     "start_time": "2021-12-06T03:38:12.355844Z"
    }
   },
   "outputs": [],
   "source": [
    "data_final_1 = data_final.drop(['DayNight_Day'] ,axis = 1)\n",
    "data_final_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533a217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.368106Z",
     "start_time": "2021-12-06T03:38:12.364489Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(data_final_1, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085ac2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.388120Z",
     "start_time": "2021-12-06T03:38:12.369267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividing the training data set into X and Y\n",
    "y_train = df_train.pop('Total_arrests')\n",
    "X_train = df_train\n",
    "\n",
    "#Build a linear model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "\n",
    "lr_1 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "lr_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fade22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.411579Z",
     "start_time": "2021-12-06T03:38:12.390002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for the VIF values of the variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Creating a dataframe that will contain the names of all the feature variables and their VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9629457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.517337Z",
     "start_time": "2021-12-06T03:38:12.413025Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "y_train_predicted = lr_1.predict(X_train_lm)\n",
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_predicted), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81d0f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.522201Z",
     "start_time": "2021-12-06T03:38:12.518961Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(data_final_1, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3aa4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.528346Z",
     "start_time": "2021-12-06T03:38:12.523310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividing the training data set into X and Y\n",
    "y_test = df_train.pop('Total_arrests')\n",
    "X_test = df_train\n",
    "\n",
    "# Now let's use our model to make predictions.\n",
    "\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_test_new = X_test[X_train.columns]\n",
    "\n",
    "# Adding a constant variable \n",
    "X_test_new = sm.add_constant(X_test)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = lr_1.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8a8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:38:12.532609Z",
     "start_time": "2021-12-06T03:38:12.529440Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95649f",
   "metadata": {},
   "source": [
    "The R² value for the test data = 0.5019859072012338, which is pretty similar to the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900a73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
